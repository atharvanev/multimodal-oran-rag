{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4d8cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prime/miniconda3/envs/marker/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "from typing import Optional, Dict, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f25564",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagramCaptioner:\n",
    "    def __init__(self, model_name: str = \"Salesforce/instructblip-flan-t5-xl\"):\n",
    "        \n",
    "        #check which device is being used\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Loading model on device: {self.device}\")\n",
    "        self.model = InstructBlipForConditionalGeneration.from_pretrained(model_name)\n",
    "        self.processor = InstructBlipProcessor.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.prompt =\"\"\"\n",
    "        \n",
    "        You are a helpful assistant that generates captions for diagrams. \n",
    "        That retains all the important information in the diagram. The caption should be concise and information rich. \n",
    "        The caption should be in English. It should be capable of replacing the diagram in a document.\n",
    "\n",
    "        If it is a flowchart, \n",
    "            Describe this flowchart diagram by listing:\n",
    "            1. Each step or decision point in order\n",
    "            2. The flow direction between elements\n",
    "            3. Any conditional branches or loops\n",
    "            4. The start and end points\n",
    "            \n",
    "            Format your response as a clear description of the process flow.\n",
    "\n",
    "        If it has arctectural elements:\n",
    "            Describe this architecture diagram by identifying:\n",
    "            1. All components and their names as shown\n",
    "            2. The connections between components\n",
    "            3. Any data flow or communication paths\n",
    "            4. The overall system structure\n",
    "            \n",
    "            Provide a clear description of the architectural layout and relationships.\n",
    "        \"\"\"\n",
    "    \n",
    "    def caption_image(self,\n",
    "                      image: Image.Image, #required type for PIL images\n",
    "                      prompt: Optional[str] = None,\n",
    "                      kwargs: Optional[Dict[str, Any]] = None) -> str:\n",
    "        if prompt is None:\n",
    "            prompt = self.prompt\n",
    "\n",
    "        defualt_kwargs = {\n",
    "            \"do_sample\": True,\n",
    "            \"num_beams\": 5,\n",
    "            \"max_length\": 512,\n",
    "            \"min_length\": 1,\n",
    "            \"top_p\": 0.9,\n",
    "            \"repetition_penalty\": 1,\n",
    "            \"length_penalty\": 1.0,\n",
    "            \"temperature\": 1.4,\n",
    "            }\n",
    "        \n",
    "        if kwargs:\n",
    "            defualt_kwargs.update(kwargs)\n",
    "\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        try:\n",
    "            inputs = self.processor(images=image, text=prompt, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "            outputs = self.model.generate(**inputs, **defualt_kwargs)\n",
    "\n",
    "            generated_caption = self.processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "        finally:\n",
    "            del inputs\n",
    "            if 'outputs' in locals():\n",
    "                del outputs\n",
    "            \n",
    "            # Clear GPU cache of unused tensors\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        return generated_caption\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adad01e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  7.25it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If it is a flowchart, describe this flowchart diagram by listing: 1. Each step or decision point in order 2. The flow direction between elements 3. Any conditional branches or loops 4. The start and end points Format your response in a clear description of the process flow. If it has arctectural elements: Describe this architecture diagram by identifying: 1. All components and their names as shown 2. The connections between components 3. Any data flow or communication paths 4. The overall system structure Provide a clear description of the architectural layout and relationships.\n"
     ]
    }
   ],
   "source": [
    "captioner = DiagramCaptioner() \n",
    "res = captioner.caption_image(\n",
    "    image=Image.open(\"Images/O-RAN.WG3.TS.E2AP-R004-v07.00 (1)/page41_img2.png\").convert(\"RGB\")\n",
    ")\n",
    "\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
